{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings; warnings.filterwarnings(action='once')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import missingno as msno\n",
    "from sklearn import metrics\n",
    "\n",
    "from tpot import TPOTRegressor\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "df_regression = pd.read_csv(\"regression_df.csv\", index_col=\"timestamp\")\n",
    "df_ln_regression = pd.read_csv(\"ln_regression_df.csv\", index_col=\"timestamp\") \n",
    "\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "def get_tpot_pipe_regression():\n",
    "    \n",
    "    X = df_regression.iloc[:, :-1]\n",
    "    y = df_regression.iloc[:, -1].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.70, shuffle=False)\n",
    "    \n",
    "    \n",
    "    tpot = TPOTRegressor(generations=5, population_size=20, verbosity=2,\n",
    "                          random_state=42, cv=cv, n_jobs=-1, config_dict=\"TPOT light\")\n",
    "    tpot.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = tpot.predict(X_test)\n",
    "    \n",
    "\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    rmse = metrics.mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"The model performance for testing set\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print('MAE is {}'.format(mae))\n",
    "    print('MSE is {}'.format(mse))\n",
    "    print('RMSE is {}'.format(rmse))\n",
    "    print('R2 score is {}'.format(r2))\n",
    "    \n",
    "    print(\"TPOT:\")\n",
    "    print(tpot.score(X_test, y_test))\n",
    "    tpot.export('tpot_pipe_regression.py')\n",
    "\n",
    "def get_tpot_pipe_ln_regression():\n",
    "    \n",
    "    X = df_ln_regression.iloc[:, :-1]\n",
    "    y = df_ln_regression.iloc[:, -1].values\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.70, shuffle=False)\n",
    "    \n",
    "    \n",
    "    tpot = TPOTRegressor(generations=5, population_size=20,\n",
    "                          verbosity=2, random_state=42, \n",
    "                          cv=cv, n_jobs=-1, config_dict=\"TPOT light\")\n",
    "    \n",
    "    tpot.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = tpot.predict(X_test)\n",
    "\n",
    "    mae = metrics.mean_absolute_error(y_test, y_pred)\n",
    "    rmse = metrics.mean_squared_error(y_test, y_pred, squared=False)\n",
    "    mse = metrics.mean_squared_error(y_test, y_pred)\n",
    "    r2 = metrics.r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"The model performance for testing set\")\n",
    "    print(\"--------------------------------------\")\n",
    "    print('MAE is {}'.format(mae))\n",
    "    print('MSE is {}'.format(mse))\n",
    "    print('RMSE is {}'.format(rmse))\n",
    "    print('R2 score is {}'.format(r2))\n",
    "    \n",
    "    print(\"TPOT:\")\n",
    "    print(tpot.score(X_test, y_test))\n",
    "    tpot.export('tpot_pipe_ln_regression.py')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings; warnings.filterwarnings(action='once')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import missingno as msno\n",
    "\n",
    "large = 22; med = 16; small = 12\n",
    "params = {'axes.titlesize': large,\n",
    "          'legend.fontsize': med,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'xtick.labelsize': med,\n",
    "          'ytick.labelsize': med,\n",
    "          'figure.titlesize': large}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "df_classification_binary_4_days = pd.read_csv(\"binary_danger_window_4_days_df.csv\", index_col=\"timestamp\")\n",
    "\n",
    "X = df_classification_binary_4_days.iloc[:, :-1]\n",
    "y = df_classification_binary_4_days.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.70, shuffle=False)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "def get_tpot_pipe_binary_4(scoring):\n",
    "    tpot = TPOTClassifier(generations=5, population_size=20,\n",
    "                          verbosity=2, random_state=42, scoring=scoring, \n",
    "                          cv=cv, n_jobs=-1)\n",
    "    \n",
    "    tpot.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = tpot.predict(X_test)\n",
    "\n",
    "    print(\"Optimized Metric: \" + scoring)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_mat)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\",)\n",
    "    print (classification_rep)\n",
    "    print(\"TPOT:\")\n",
    "    print(tpot.score(X_test, y_test))\n",
    "    tpot.export('tpot_pipe_binary_4_%s.py'%(scoring))\n",
    "    \n",
    "# try:\n",
    "#     get_tpot_pipe_binary_4(\"precision\")\n",
    "# except:\n",
    "#     pass\n",
    "# try:\n",
    "#     get_tpot_pipe_binary_4(\"f1\")\n",
    "# except:\n",
    "#     pass\n",
    "# try:\n",
    "#     get_tpot_pipe_binary_4(\"accuracy\")\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.097676164263598 149.33333333333334\n"
     ]
    }
   ],
   "source": [
    "warnings_not_danger =(202) / (202 + 127690) * 1440 * 4\n",
    "warnings_danger = 679 / (25511+679) * 1440 * 4\n",
    "\n",
    "print(warnings_not_danger, warnings_danger)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series = pd.Series(y_test) * 1\n",
    "# series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series = pd.Series(y_train) * 1\n",
    "# series.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc1cf4fea5304d1085bcb91326c62887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped pipeline #4 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #6 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #8 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #10 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #13 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #15 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #17 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #19 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #21 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #23 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #25 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #28 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #30 due to time out. Continuing to the next pipeline.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty..\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 '(slice(None, None, None), 0)' is an invalid key.\n",
      "Skipped pipeline #34 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #36 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #38 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #43 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #45 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #47 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #49 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #51 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #53 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #56 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #59 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #61 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #63 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #65 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 1 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.4322374123147435\tBernoulliNB(input_matrix, BernoulliNB__alpha=10.0, BernoulliNB__fit_prior=False)\n",
      "\n",
      "-2\t0.6601341958826545\tGaussianNB(PCA(input_matrix, PCA__iterated_power=3, PCA__svd_solver=randomized))\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "Skipped pipeline #68 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #71 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #73 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #75 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #77 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #79 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #81 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #85 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #87 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #89 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #91 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #93 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #95 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #97 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #99 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #101 due to time out. Continuing to the next pipeline.\n",
      "Skipped pipeline #103 due to time out. Continuing to the next pipeline.\n",
      "\n",
      "Generation 2 - Current Pareto front scores:\n",
      "\n",
      "-1\t0.4322374123147435\tBernoulliNB(input_matrix, BernoulliNB__alpha=10.0, BernoulliNB__fit_prior=False)\n",
      "\n",
      "-2\t0.6601341958826545\tGaussianNB(PCA(input_matrix, PCA__iterated_power=3, PCA__svd_solver=randomized))\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Unsupported set of arguments: The combination of penalty='l2' and loss='hinge' are not supported when dual=False, Parameters: penalty='l2', loss='hinge', dual=False.\n",
      "_pre_test decorator: _random_mutation_operator: num_test=0 Found array with 0 feature(s) (shape=(50, 0)) while a minimum of 1 is required..\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "Pipeline encountered that has previously been evaluated during the optimization process. Using the score from the previous evaluation.\n",
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "Optimized Metric: f1\n",
      "Confusion Matrix:\n",
      "[[19487 40789]\n",
      " [ 5100   659]]\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.79      0.32      0.46     60276\n",
      "        True       0.02      0.11      0.03      5759\n",
      "\n",
      "    accuracy                           0.31     66035\n",
      "   macro avg       0.40      0.22      0.24     66035\n",
      "weighted avg       0.72      0.31      0.42     66035\n",
      "\n",
      "TPOT:\n",
      "0.02791958819666575\n",
      "32 operators have been imported by TPOT.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bca0bd58e774553b6491091b4586e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Optimization Progress:   0%|          | 0/120 [00:00<?, ?pipeline/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "import warnings; warnings.filterwarnings(action='once')\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import missingno as msno\n",
    "\n",
    "large = 22; med = 16; small = 12\n",
    "params = {'axes.titlesize': large,\n",
    "          'legend.fontsize': med,\n",
    "          'figure.figsize': (16, 10),\n",
    "          'axes.labelsize': med,\n",
    "          'axes.titlesize': med,\n",
    "          'xtick.labelsize': med,\n",
    "          'ytick.labelsize': med,\n",
    "          'figure.titlesize': large}\n",
    "plt.rcParams.update(params)\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "\n",
    "from tpot import TPOTClassifier\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "df_classification_binary_4_days = pd.read_csv(\"binary_danger_window_4_days_df.csv\", index_col=\"timestamp\")\n",
    "\n",
    "X = df_classification_binary_4_days.iloc[:, :-1]\n",
    "y = df_classification_binary_4_days.iloc[:, -1].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.70, shuffle=False)\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "def get_tpot_pipe_binary_4_70train(scoring):\n",
    "    tpot = TPOTClassifier(generations=5, population_size=20,\n",
    "                          verbosity=3, random_state=42, scoring=scoring, \n",
    "                          cv=cv, n_jobs=-1)\n",
    "    \n",
    "    tpot.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = tpot.predict(X_test)\n",
    "\n",
    "    print(\"Optimized Metric: \" + scoring)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred)\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(confusion_mat)\n",
    "    classification_rep = classification_report(y_test, y_pred)\n",
    "    print(\"Classification Report:\",)\n",
    "    print (classification_rep)\n",
    "    print(\"TPOT:\")\n",
    "    print(tpot.score(X_test, y_test))\n",
    "    tpot.export('tpot_pipe_binary_4_%s_70train.py'%(scoring))\n",
    "    \n",
    "try:\n",
    "    get_tpot_pipe_binary_4_70train(\"f1\")\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    get_tpot_pipe_binary_4_70train(\"accuracy\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.333333333333336"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1440 * 679/(25511+679)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
